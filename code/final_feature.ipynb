{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "635C8ED2C5BD44898E9BA63ECF20535C",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 显示cell运行时长\n",
    "%load_ext klab-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9262319FE1314DF383E86B79690342DD",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import psutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AA50B42EA39B41788C9E46AAB38C1376",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.44 ms\n"
     ]
    }
   ],
   "source": [
    "app_type={'user_id':np.uint32,'day':np.uint8}\n",
    "act_type={'user_id':np.uint32,'day':np.uint8,'page':np.uint8,'video_id':np.uint32,'author_id':np.uint32,'action_type':np.uint8}\n",
    "reg_type = {'user_id':np.uint32,'register_day':np.uint8,'register_type':np.uint8,'device_type':np.uint8}\n",
    "video_type={'user_id':np.uint32,'day':np.uint8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8486EA4EC46342C88A2FACDFE3BD40B8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/datasets/fusai/\"\n",
    "app = pd.read_csv(path+\"app_launch_log.txt\",names=['user_id','day'],encoding='utf-8',dtype=app_type,sep=\"\\t\")\n",
    "user_act = pd.read_table(path+'user_activity_log.txt',names=['user_id','day','page','video_id','author_id','action_type'],encoding='utf-8',dtype=act_type,sep='\\t')\n",
    "user_reg = pd.read_table(path+'user_register_log.txt',names=['user_id','register_day','register_type','device_type'],encoding='utf-8',dtype=reg_type,sep='\\t')\n",
    "video = pd.read_table(path+'video_create_log.txt',names=['user_id','day'],dtype=video_type,encoding='utf-8',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E36077CBC99244CD8F837F5CA8BCA4D6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.42 ms\n"
     ]
    }
   ],
   "source": [
    "def getMemCpu():\n",
    "    data = psutil.virtual_memory()\n",
    "    total = data.total #总内存,单位为byte\n",
    "    free = data.available #可以内存\n",
    "    memory =  \"Memory usage:%d\"%(int(round(data.percent)))+\"%\"+\"  \"\n",
    "    cpu = \"CPU:%0.2f\"%psutil.cpu_percent(interval=1)+\"%\"\n",
    "    return memory+cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6D9D8C817588464D8B14CA6042B30622",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.5 ms\n"
     ]
    }
   ],
   "source": [
    "def get_last_day_count(d,data,row_name):\n",
    "    data = data[data.day>d]\n",
    "    last_day_count = data[['user_id','day']].groupby('user_id')['day'].agg({(row_name+\"days_counts\",'count')}).reset_index()\n",
    "    return last_day_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "48ABF7EE59394F35898F37EE0B9CA11C",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.86 ms\n"
     ]
    }
   ],
   "source": [
    "#求最后一次与前一次的差\n",
    "def get_last_gap(s):\n",
    "    s = list(s)\n",
    "    n = len(s)\n",
    "    if n<2:\n",
    "        return None\n",
    "    s.sort()\n",
    "    return s[n-1]-s[n-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "78ABDCE1DF9946B38EDB11158E820B20",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.24 ms\n"
     ]
    }
   ],
   "source": [
    "#求连续行为天数的最大值\n",
    "def get_continue_counts(data):\n",
    "    data = np.array(data)\n",
    "    i=0\n",
    "    count = 1\n",
    "    max_num = 0\n",
    "    while i<len(data)-1:\n",
    "        if data[i+1]-data[i] == 1:\n",
    "            count += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            if max_num < count:\n",
    "                max_num = count\n",
    "            i += 1\n",
    "            count = 1\n",
    "    if max_num < count :\n",
    "        max_num = count\n",
    "    return max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "626ED57975E54DE986112EF4B9EEF7E9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.23 ms\n"
     ]
    }
   ],
   "source": [
    "#求连续行为天数的均值\n",
    "def get_continue_mean(data):\n",
    "    data = np.array(data)\n",
    "    i=0\n",
    "    count = 1\n",
    "    count_arr = []\n",
    "    while i<len(data)-1:\n",
    "        if data[i+1]-data[i] == 1:\n",
    "            count += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            count_arr.append(count)\n",
    "            i += 1\n",
    "            count = 1\n",
    "    count_arr.append(count)\n",
    "    return np.mean(count_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "12AC8BA0E47E4197BAD6E3BA2F8FC32B",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "#求连续行为天数的方差\n",
    "def get_continue_std(data):\n",
    "    data = np.array(data)\n",
    "    i=0\n",
    "    count = 1\n",
    "    count_arr = []\n",
    "    ans = []\n",
    "    while i<len(data)-1:\n",
    "        if data[i+1]-data[i] == 1:\n",
    "            count += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            count_arr.append(count)\n",
    "            i += 1\n",
    "            count = 1\n",
    "    count_arr.append(count)\n",
    "    return np.std(count_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "B4FEA6578DBB4CD58E9AF94C62C6C35F",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3 ms\n"
     ]
    }
   ],
   "source": [
    "def cal_kurt(data):\n",
    "    return data.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "A39FEBD6A08A46B3AA166A136DF25F6A",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.2 ms\n"
     ]
    }
   ],
   "source": [
    "#一阶差分后求特征\n",
    "def diff_feature(row_name,data):\n",
    "    diff_feature=[]\n",
    "    if 'day' in data.columns.values.tolist():\n",
    "        user_day='day' \n",
    "    else:\n",
    "        user_day='register_day'\n",
    "    diff_feature = data.sort_values(by=['user_id',user_day])\n",
    "\n",
    "    diff_feature['diff']=data.groupby('user_id')[user_day].diff().fillna(0).astype(\"float32\")\n",
    "    diff_feature.drop(columns=[user_day],inplace=True)\n",
    "    \n",
    "    diff_fun = {(row_name+'sum','sum'),(row_name+'var','var'),(row_name+'mean','mean'),(row_name+'max','max'),\n",
    "            (row_name+'std','std'),(row_name+'min','min'),(row_name+'count','count'),(row_name+'skew','skew'),\n",
    "            (row_name+'kurt',cal_kurt)\n",
    "    }\n",
    "    diff = []\n",
    "    diff = diff_feature.groupby('user_id')['diff'].agg(diff_fun).astype(\"float32\").reset_index()\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FD857FC4A01A4EF299E3ED14EFCE59A7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.29 ms\n"
     ]
    }
   ],
   "source": [
    "#对时间求特征\n",
    "def day_feature(row_name,data):\n",
    "    day_feature =[]\n",
    "    if 'day' in data.columns.values.tolist():\n",
    "        user_day='day' \n",
    "    else:\n",
    "        user_day='register_day'\n",
    "        \n",
    "    day_fun = {(row_name+'sum','sum'),(row_name+'var','var'),(row_name+'count','count'),(row_name+'std','std'),\n",
    "                (row_name+'max','max'),(row_name+'mean','mean'),(row_name+'min','min'),(row_name+'skew','skew'),\n",
    "                (row_name+'kurt',cal_kurt)\n",
    "    }\n",
    "    day_feature = data.groupby('user_id')[user_day].agg(day_fun).astype(\"float32\").reset_index()\n",
    "    return day_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8E2D265154B5477D8EC26F42A7C978D7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "def cal_feature_counts(row_name,data,c_name):\n",
    "    \n",
    "    cal_count=[]\n",
    "    # data = data[data.day>7]\n",
    "    cal_count = data.groupby(['user_id',c_name]).size().rename(\"column_counts\").reset_index()\n",
    "    newDF = pd.DataFrame()\n",
    "    newDF['user_id'] = cal_count['user_id'].unique()\n",
    "    days = list(data[c_name].unique())\n",
    "    for c in days:\n",
    "        col_name = '{}_count'.format(str(row_name) + str(c))\n",
    "        cal_count = data[data[c_name]==c].groupby(['user_id']).size().astype(\"float32\").rename(col_name).reset_index()\n",
    "        newDF = pd.merge(newDF,cal_count,on=['user_id'],how='left')\n",
    "    return newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "A2204C69A3E24277A81ADEA69D599FC8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "def app_feature(beginday,endday):\n",
    "    \n",
    "    info = getMemCpu()\n",
    "    start = time.clock()\n",
    "    \n",
    "    app_content = app[(app.day>=beginday)&(app.day<=endday)]\n",
    "    app_content.day = app_content.day - beginday + 1\n",
    "    \n",
    "    app_feature = day_feature('app_day_',app_content)\n",
    "    \n",
    "    diff = diff_feature('app_day_diff_',app_content)\n",
    "    app_feature = pd.merge(app_feature,diff,on=['user_id'],how='left')\n",
    "    del diff\n",
    "    gc.collect()\n",
    "    \n",
    "    app_nums=app_content.groupby('user_id')['day'].nunique().astype(\"float32\").reset_index().rename(columns={'day':'app_nums'})\n",
    "    app_feature = pd.merge(app_feature,app_nums,on=['user_id'],how='left')\n",
    "    print(\"app_nums\")\n",
    "    del app_nums\n",
    "    gc.collect()\n",
    "    \n",
    "    gp = app_content[['user_id','day']].groupby(['user_id'])['day'].unique().apply(get_last_gap).astype(\"float32\").rename('app_last_gap').reset_index()\n",
    "    app_feature = pd.merge(app_feature,gp,on=['user_id'],how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    \n",
    "    app_continue_std = app_content[['user_id','day']].groupby(['user_id'])['day'].unique().apply(get_continue_std).rename('app_continue_std').astype(\"float32\").reset_index()\n",
    "    app_feature = pd.merge(app_feature,app_continue_std,on=['user_id'],how='left')\n",
    "    del app_continue_std\n",
    "    gc.collect()\n",
    "    \n",
    "    app_continue_mean = app_content[['user_id','day']].groupby(['user_id'])['day'].unique().apply(get_continue_mean).rename('app_continue_mean').astype(\"float32\").reset_index()\n",
    "    app_feature = pd.merge(app_feature,app_continue_mean,on=['user_id'],how='left')\n",
    "    del app_continue_mean\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last1days_counts = get_last_day_count(15,app_content,\"app_last1\")\n",
    "    app_feature = pd.merge(app_feature,app_last1days_counts,on=['user_id'],how='left')\n",
    "    del app_last1days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last2days_counts = get_last_day_count(14,app_content,\"app_last2\")\n",
    "    app_feature = pd.merge(app_feature,app_last2days_counts,on=['user_id'],how='left')\n",
    "    del app_last2days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last3days_counts = get_last_day_count(13,app_content,\"app_last3\")\n",
    "    app_feature = pd.merge(app_feature,app_last3days_counts,on=['user_id'],how='left')\n",
    "    del app_last3days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last4days_counts = get_last_day_count(12,app_content,\"app_last4\")\n",
    "    app_feature = pd.merge(app_feature,app_last4days_counts,on=['user_id'],how='left')\n",
    "    del app_last4days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last5days_counts = get_last_day_count(11,app_content,\"app_last5\")\n",
    "    app_feature = pd.merge(app_feature,app_last5days_counts,on=['user_id'],how='left')\n",
    "    del app_last5days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last6days_counts = get_last_day_count(10,app_content,\"app_last6\")\n",
    "    app_feature = pd.merge(app_feature,app_last6days_counts,on=['user_id'],how='left')\n",
    "    del app_last6days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    app_last7days_counts = get_last_day_count(9,app_content,\"app_last7\")\n",
    "    app_feature = pd.merge(app_feature,app_last7days_counts,on=['user_id'],how='left')\n",
    "    del app_last7days_counts\n",
    "    gc.collect()\n",
    "    \t\n",
    "    end = time.clock()\n",
    "    print(info+\"\\b\"*(len(info)+1))\n",
    "    print('Running time: %s Seconds'%(end-start))\n",
    "    \n",
    "    return app_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "D96EEDC63BA1474897E4825ABB4E917D",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.54 ms\n"
     ]
    }
   ],
   "source": [
    "def video_feature(beginday,endday):\n",
    "    \n",
    "    info = getMemCpu()\n",
    "    start = time.clock()\n",
    "    \n",
    "    video_content = video[(video.day>=beginday)&(video.day<=endday)]\n",
    "    video_content.day = video_content.day - beginday+1\n",
    "    \n",
    "    video_feature = day_feature('video_day_',video_content)\n",
    "    \n",
    "    video_nums=video_content.groupby('user_id')['day'].nunique().astype(\"float32\").reset_index().rename(columns={'day':'video_nums'})\n",
    "    video_feature = pd.merge(video_feature,video_nums,on=['user_id'],how='left')\n",
    "    print(\"video_nums\")\n",
    "    del video_nums\n",
    "    gc.collect()\n",
    "    \n",
    "    # video_last1days_counts = get_last_day_count(15,video_content,\"video_last1\")\n",
    "    # app_feature = pd.merge(video_feature,video_last1days_counts,on=['user_id'],how='left')\n",
    "    # del video_last1days_counts\n",
    "    # gc.collect()\n",
    "    \n",
    "    # video_last2days_counts = get_last_day_count(14,video_content,\"video_last2\")\n",
    "    # video_feature = pd.merge(video_feature,video_last2days_counts,on=['user_id'],how='left')\n",
    "    # del video_last2days_counts\n",
    "    # gc.collect()\n",
    "    \n",
    "    # video_last3days_counts = get_last_day_count(13,video_content,\"video_last3\")\n",
    "    # video_feature = pd.merge(video_feature,video_last3days_counts,on=['user_id'],how='left')\n",
    "    # del video_last3days_counts\n",
    "    # gc.collect()\n",
    "    \n",
    "    # video_last4days_counts = get_last_day_count(12,video_content,\"video_last4\")\n",
    "    # video_feature = pd.merge(video_feature,video_last4days_counts,on=['user_id'],how='left')\n",
    "    # del video_last4days_counts\n",
    "    # gc.collect()\n",
    "    \n",
    "    # video_last5days_counts = get_last_day_count(11,video_content,\"video_last5\")\n",
    "    # video_feature = pd.merge(video_feature,video_last5days_counts,on=['user_id'],how='left')\n",
    "    # del video_last5days_counts\n",
    "    # gc.collect()\n",
    "    \n",
    "    # video_last6days_counts = get_last_day_count(10,video_content,\"video_last6\")\n",
    "    # video_feature = pd.merge(video_feature,video_last6days_counts,on=['user_id'],how='left')\n",
    "    # del video_last6days_counts\n",
    "    # gc.collect()\n",
    "    \n",
    "    video_last7days_counts = get_last_day_count(9,video_content,\"video_last7\")\n",
    "    video_feature = pd.merge(video_feature,video_last7days_counts,on=['user_id'],how='left')\n",
    "    del video_last7days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    end = time.clock()\n",
    "    print(info+\"\\b\"*(len(info)+1))\n",
    "    print('Running time: %s Seconds'%(end-start))\n",
    "    \n",
    "    return video_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6323314FA8354BB083A725C6AD12B727",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.63 ms\n"
     ]
    }
   ],
   "source": [
    "def reg_feature(beginday,endday):\n",
    "    \n",
    "    reg_content = user_reg[(user_reg.register_day<=endday)] \n",
    "    reg_content.register_day = endday - reg_content.register_day + 1\n",
    "    \n",
    "    reg_content[\"device_type_register_count\"] = (reg_content.groupby(by=[\"device_type\", \"register_type\"])[\"register_type\"].transform(\"count\")).astype(np.uint16)\n",
    "    print(\"device_type_register_count\")\n",
    "    \n",
    "    reg_content[\"device_type_count\"] = (reg_content.groupby(by=[\"device_type\"])[\"device_type\"].transform(\"count\")).astype(np.uint16)\n",
    "    print(\"device_type_count\")\n",
    "    \n",
    "    reg_content[\"device_type_register_rate\"] = (reg_content[\"device_type_register_count\"] / (reg_content[\"device_type_count\"]+0.00001)).astype(np.float32)\n",
    "    print(\"device_type_register_rate\")\n",
    "    return reg_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DCA16F383A03406E85B27E15E2C35D94",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.6 ms\n"
     ]
    }
   ],
   "source": [
    "def act_feature(beginday,endday):\n",
    "    \n",
    "    info = getMemCpu()\n",
    "    start = time.clock()\n",
    "    \n",
    "    act_content = user_act[(user_act.day>=beginday)&(user_act.day<=endday)]\n",
    "    act_content.day = act_content.day - beginday + 1\n",
    "    \n",
    "    act_feature = day_feature('act_day_',act_content)\n",
    "    \n",
    "    act_last1days_counts = get_last_day_count(15,act_content,\"act_last1\")\n",
    "    act_feature = pd.merge(act_feature,act_last1days_counts,on=['user_id'],how='left')\n",
    "    del act_last1days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_last2days_counts = get_last_day_count(14,act_content,\"act_last2\")\n",
    "    act_feature = pd.merge(act_feature,act_last2days_counts,on=['user_id'],how='left')\n",
    "    del act_last2days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_last3days_counts = get_last_day_count(13,act_content,\"act_last3\")\n",
    "    act_feature = pd.merge(act_feature,act_last3days_counts,on=['user_id'],how='left')\n",
    "    del act_last3days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_last4days_counts = get_last_day_count(12,act_content,\"act_last4\")\n",
    "    act_feature = pd.merge(act_feature,act_last4days_counts,on=['user_id'],how='left')\n",
    "    del act_last4days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_last5days_counts = get_last_day_count(11,act_content,\"act_last5\")\n",
    "    act_feature = pd.merge(act_feature,act_last5days_counts,on=['user_id'],how='left')\n",
    "    del act_last5days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_last6days_counts = get_last_day_count(10,act_content,\"act_last6\")\n",
    "    act_feature = pd.merge(act_feature,act_last6days_counts,on=['user_id'],how='left')\n",
    "    del act_last6days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_last7days_counts = get_last_day_count(9,act_content,\"act_last7\")\n",
    "    act_feature = pd.merge(act_feature,act_last7days_counts,on=['user_id'],how='left')\n",
    "    del act_last7days_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    act_nums=act_content.groupby('user_id')['day'].nunique().astype(\"float32\").reset_index().rename(columns={'day':'act_nums'})\n",
    "    act_feature = pd.merge(act_feature,act_nums,on=['user_id'],how='left')\n",
    "    print(\"act_nums\")\n",
    "    del act_nums\n",
    "    gc.collect()\n",
    "    \n",
    "    author_nums=act_content.groupby('user_id')['author_id'].nunique().astype(\"float32\").reset_index().rename(columns={'author_id':'author_nums'})\n",
    "    act_feature = pd.merge(act_feature,author_nums,on=['user_id'],how='left')\n",
    "    print(\"author_nums\")\n",
    "    del author_nums\n",
    "    gc.collect()\n",
    "    \n",
    "    act_video_nums=act_content.groupby('user_id')['video_id'].nunique().astype(\"float32\").reset_index().rename(columns={'video_id':'act_video_nums'})\n",
    "    act_feature = pd.merge(act_feature,act_video_nums,on=['user_id'],how='left')\n",
    "    print(\"act_video_nums\")\n",
    "    del act_video_nums\n",
    "    gc.collect()\n",
    "    \n",
    "    action_type_nums=act_content.groupby('user_id')['action_type'].nunique().astype(\"float32\").reset_index().rename(columns={'action_type':'action_type_nums'})\n",
    "    act_feature = pd.merge(act_feature,action_type_nums,on=['user_id'],how='left')\n",
    "    print(\"action_type_nums\")\n",
    "    del action_type_nums\n",
    "    gc.collect()\n",
    "    # #每一个video有多少行为类型\n",
    "    # every_video_types=act_content.groupby(['user_id','video_id'])['action_type'].nunique().astype(\"float32\").reset_index().rename(columns={'action_type':'every_video_types'})\n",
    "    # act_feature = pd.merge(act_feature,every_video_types,on=['user_id'],how='left')\n",
    "    # print(\"every_video_types\")\n",
    "    # del every_video_types\n",
    "    # gc.collect()\n",
    "    \n",
    "    page_nums=act_content.groupby('user_id')['page'].nunique().astype(\"float32\").reset_index().rename(columns={'page':'page_nums'})\n",
    "    act_feature = pd.merge(act_feature,page_nums,on=['user_id'],how='left')\n",
    "    print(\"page_nums\")\n",
    "    del page_nums\n",
    "    gc.collect()\n",
    "    \n",
    "    act_continue_std = act_content[['user_id','day']].groupby(['user_id'])['day'].unique().apply(get_continue_std).rename('act_continue_std').astype(\"float32\").reset_index()\n",
    "    act_feature = pd.merge(act_feature,act_continue_std,on=['user_id'],how='left')\n",
    "    print(\"act_continue_std\")\n",
    "    del act_continue_std\n",
    "    gc.collect()\n",
    "    \n",
    "    act_continue_mean = act_content[['user_id','day']].groupby(['user_id'])['day'].unique().apply(get_continue_mean).rename('act_continue_mean').astype(\"float32\").reset_index()\n",
    "    act_feature = pd.merge(act_feature,act_continue_mean,on=['user_id'],how='left')\n",
    "    print(\"act_continue_mean\")\n",
    "    del act_continue_mean\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    gp = act_content[['user_id','day']].groupby(['user_id'])['day'].unique().apply(get_last_gap).rename('act_last_gap').reset_index()\n",
    "    act_feature = pd.merge(act_feature,gp,on=['user_id'],how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    \n",
    "    # gc.collect()\n",
    "    # diff = diff_feature('act_day_diff_',act_content)\n",
    "    # act_feature = pd.merge(act_feature,diff,on=['user_id'],how='left')\n",
    "    \n",
    "    cal_page = cal_feature_counts(\"act_page\",act_content,'page')\n",
    "    act_feature = pd.merge(act_feature,cal_page,on=['user_id'],how='left')\n",
    "    print(\"cal_page\")\n",
    "    del cal_page\n",
    "    gc.collect()\n",
    "    \n",
    "    cal_act_type = cal_feature_counts(\"act_type\",act_content,'action_type')\n",
    "    act_feature = pd.merge(act_feature,cal_act_type,on=['user_id'],how='left')\n",
    "    print(\"cal_act_type\")\n",
    "    del cal_act_type\n",
    "    gc.collect()\n",
    "    \n",
    "    author_counts = []\n",
    "    author_counts = act_content.groupby(['user_id'])['author_id'].agg({(\"act_author_counts\",\"count\")}).reset_index()\n",
    "    act_feature = pd.merge(act_feature,author_counts,on=['user_id'],how='left')\n",
    "    print(\"author_counts\")\n",
    "    del author_counts\n",
    "    gc.collect()\n",
    "    \n",
    "    gc.collect()\n",
    "    author_count = []\n",
    "    authors = act_content.groupby(['user_id','author_id'])['author_id'].agg({(\"act_author_count\",\"count\")}).reset_index()\n",
    "    aut_fun = {('act_author_mean','mean'),('act_author_std','std'),('act_author_count','count')}\n",
    "    author_count = authors.groupby(\"user_id\")[\"author_id\"].agg(aut_fun).reset_index()\n",
    "    act_feature = pd.merge(act_feature,author_count,on=['user_id'],how='left')\n",
    "    print(\"author_count\")\n",
    "    del author_count,authors\n",
    "    gc.collect()\n",
    "    \n",
    "    eachday_acts=act_content.groupby(['user_id','day'])['day'].agg({('eachday_acts','count')}).reset_index()\n",
    "    act_everyday_fun={('act_daily_max','max')}\n",
    "    acts_daily_action=eachday_acts.groupby('user_id')['eachday_acts'].agg(act_everyday_fun).reset_index()\n",
    "    act_feature = pd.merge(act_feature,acts_daily_action,on=['user_id'],how='left')\n",
    "    print(\"acts_daily_action\")\n",
    "    del acts_daily_action,eachday_acts\n",
    "    gc.collect()\n",
    "    \n",
    "    #单个视频、作者最大行为数\n",
    "    gc.collect()\n",
    "    acts_single_video=act_content.groupby(['user_id','video_id'])['video_id'].agg({('acts_single_video','count')}).reset_index()\n",
    "    act_single_video_fun={('single_video_max','max')}\n",
    "    acts_single_video_action=acts_single_video.groupby('user_id')['acts_single_video'].agg(act_single_video_fun).reset_index()\n",
    "    act_feature = pd.merge(act_feature,acts_single_video_action,on=['user_id'],how='left')\n",
    "    print(\"acts_single_video_action\")\n",
    "    del acts_single_video,acts_single_video_action\n",
    "    gc.collect()\n",
    "    \n",
    "    #同一个video的行为种类——>>平均每个video上的行为种类\n",
    "    a_types=act_content.groupby(['user_id','video_id'])['action_type'].agg({('types_video','count')}).reset_index()\n",
    "    act_type_fun={('every_video_type_mean','mean')}\n",
    "    types_video_action=a_types.groupby('user_id')['types_video'].agg(act_type_fun).reset_index()\n",
    "    act_feature = pd.merge(act_feature,types_video_action,on=['user_id'],how='left')\n",
    "    print(\"types_video_action\")\n",
    "    del a_types,types_video_action\n",
    "    gc.collect()\n",
    "    \n",
    "    #行为日志，每天浏览页面种类平均数\n",
    "    page_types=act_content.groupby(['user_id','day'])['page'].agg({('page_types','count')}).reset_index()\n",
    "    page_type_fun={('every_page_type_mean','mean')}\n",
    "    every_page_type_action=page_types.groupby('user_id')['page_types'].agg(page_type_fun).reset_index()\n",
    "    act_feature = pd.merge(act_feature,every_page_type_action,on=['user_id'],how='left')\n",
    "    print(\"every_page_type_action\")\n",
    "    del page_types,every_page_type_action\n",
    "    gc.collect()\n",
    "    \n",
    "    end = time.clock()\n",
    "    print(info+\"\\b\"*(len(info)+1))\n",
    "    print('Running time: %s Seconds'%(end-start))\n",
    "    return act_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "437F8B900B52433C87E320EFB18B16CE",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.49 ms\n"
     ]
    }
   ],
   "source": [
    "def merge_feature(reg_feature,act_feature,video_feature,app_feature):\n",
    "\n",
    "    #train_feature = []\n",
    "    train_feature = reg_feature\n",
    "    train_feature = pd.merge(train_feature,act_feature,on=['user_id'],how='left')\n",
    "    train_feature = pd.merge(train_feature,video_feature,on=['user_id'],how='left')\n",
    "    train_feature = pd.merge(train_feature,app_feature,on=['user_id'],how='left')\n",
    "    return train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0A1B767E6E744D3A974466B47D9C78CC",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.62 ms\n"
     ]
    }
   ],
   "source": [
    "def is_active(df,d1,d2):\n",
    "    gp1 = app[(app.day>=d1) & (app.day<=d2)][['user_id']].groupby(['user_id']).size().rename('app').reset_index()\n",
    "    gp2 = video[(video.day>=d1) & (video.day<=d2)][['user_id']].groupby(['user_id']).size().rename('video').reset_index()\n",
    "    gp3 = user_act[(user_act.day>=d1) & (user_act.day<=d2)][['user_id']].groupby(['user_id']).size().rename('act').reset_index()\n",
    "    \n",
    "    df = df.merge(gp1,on=['user_id'],how='left')\n",
    "    df = df.merge(gp2,on=['user_id'],how='left')\n",
    "    df = df.merge(gp3,on=['user_id'],how='left')\n",
    "    \n",
    "    df['app'] = df['app'].fillna(0)\n",
    "    df['video'] = df['video'].fillna(0)\n",
    "    df['act'] = df['act'].fillna(0)\n",
    "    df['count'] = df['app']+df['video']+df['act']\n",
    "    \n",
    "    def isnotzero(x):\n",
    "        if x>0:\n",
    "            return 1\n",
    "        return 0\n",
    "    y = df['count'].apply(isnotzero)\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "293AB9E3A21C4FFB8212313BF20A12B8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "mkdir /home/kesci/bigdata/train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8BE8C79D5F824B4AA6C5EC1D6213C681",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.2 s\n"
     ]
    }
   ],
   "source": [
    "reg3 = reg_feature(15,30)\n",
    "# reg3.to_csv(\"/home/kesci/bigdata/train3/reg3.csv\",index = False)\n",
    "\n",
    "act3 = act_feature(15,30)\n",
    "# act3.to_csv(\"/home/kesci/bigdata/train3/act3.csv\",index = False)\n",
    "\n",
    "app3 = app_feature(15,30)\n",
    "# app3.to_csv(\"/home/kesci/bigdata/train3/app3.csv\",index = False)\n",
    "\n",
    "video3 = video_feature(15,30)\n",
    "# video3.to_csv(\"/home/kesci/bigdata/train3/video3.csv\",index = False)\n",
    "\n",
    "train3_feature = merge_feature(reg3,act3,video3,app3)\n",
    "train3_feature.to_csv(\"/home/kesci/bigdata/train3/fuck3_feature.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "00A2CCE9616042FCA05662D4AC49EBBA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_type_register_count\n",
      "device_type_count\n",
      "device_type_register_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_nums\n",
      "author_nums\n",
      "act_video_nums\n",
      "action_type_nums\n",
      "page_nums\n",
      "act_continue_std\n",
      "act_continue_mean\n",
      "cal_page\n",
      "cal_act_type\n",
      "author_counts\n",
      "author_count\n",
      "acts_daily_action\n",
      "acts_single_video_action\n",
      "types_video_action\n",
      "every_page_type_action\n",
      "Memory usage:32%  CPU:25.50%\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Running time: 1357.014658 Seconds\n",
      "app_nums\n",
      "Memory usage:42%  CPU:25.40%\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Running time: 457.50469499999963 Seconds\n",
      "video_nums\n",
      "Memory usage:32%  CPU:25.40%\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Running time: 15.265809999999874 Seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31min 18s\n"
     ]
    }
   ],
   "source": [
    "del reg3,video3,act3,app3,train3_feature\n",
    "gc.collect()\n",
    "reg2 = reg_feature(8,23)\n",
    "act2 = act_feature(8,23)\n",
    "app2 = app_feature(8,23)\n",
    "video2 = video_feature(8,23)\n",
    "train2_feature = merge_feature(reg2,act2,video2,app2)\n",
    "label2 = is_active(train2_feature,24,30)\n",
    "train2_feature['label'] = label2\n",
    "train2_feature.to_csv(\"/home/kesci/bigdata/train2/fuck2_feature.csv\",index = False)\n",
    "del reg2,video2,act2,app2,train2_feature\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EDC096916E564916879C01B7704A7C0D",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_type_register_count\n",
      "device_type_count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_type_register_rate\n",
      "act_nums\n",
      "author_nums\n",
      "act_video_nums\n",
      "action_type_nums\n",
      "page_nums\n",
      "act_continue_std\n",
      "act_continue_mean\n",
      "cal_page\n",
      "cal_act_type\n",
      "author_counts\n",
      "author_count\n",
      "acts_daily_action\n",
      "acts_single_video_action\n",
      "types_video_action\n",
      "every_page_type_action\n",
      "Memory usage:32%  CPU:25.60%\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Running time: 755.4405539999998 Seconds\n",
      "app_nums\n",
      "Memory usage:35%  CPU:25.70%\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Running time: 319.94611800000075 Seconds\n",
      "video_nums\n",
      "Memory usage:32%  CPU:25.40%\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Running time: 10.32046999999966 Seconds\n",
      "time: 18min 38s\n"
     ]
    }
   ],
   "source": [
    "reg1 = reg_feature(1,16)\n",
    "act1 = act_feature(1,16)\n",
    "app1 = app_feature(1,16)\n",
    "video1 = video_feature(1,16)\n",
    "train1_feature = merge_feature(reg1,act1,video1,app1)\n",
    "label1 = is_active(train1_feature,17,23)\n",
    "train1_feature['label'] = label1\n",
    "train1_feature.to_csv(\"/home/kesci/bigdata/train1/fuck1_feature.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AF3B58B212E64363B2ADF0AF99845419"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
